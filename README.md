# Natural-Language-Processing

Technology: Python, Google Collab.
•	Programmed the bigram model with and without add-one Laplace smoothing for a given corpus.
•	Computed positive pointwise mutual information for terms and context word with/out add-2 smoothing.
•	Implemented HMM and the Viterbi algorithm to assign POS tags to given text.
•	Trained and evaluated a feed-forward neural model on Reuters corpus using Google Collab and varying the parameters for best efficiency and accuracy.

HOMEWORK 1
  1. Regular Expressions
  2. N-Grams
  3. Vector Semantics
  4. Part-of-Speech Tagging
  
HOMEWORK 2
  1. CKY PARSER
  2. Statistical Parsing
  3. Semantic Role Labeling

HOMEWORK 3
  1. Simple LESK Word Sense Disambiguation
  2. Information Extraction
